{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b1924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the search space\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from naslib.search_spaces import NasBench201SearchSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e27a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new search space object. This object doesn't have an architecture\n",
    "# assigned to it yet\n",
    "graph = NasBench201SearchSpace(n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c136cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 0, 3, 1, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample a random architecture\n",
    "# You can call this method only once.\n",
    "graph.sample_random_architecture()\n",
    "\n",
    "# Get the NASLib representation of this architecture\n",
    "graph.get_hash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fbcc3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "# This graph is now a NAS-Bench-201 model, which can be used for training\n",
    "# Forward pass some dummy data through it to see it in action\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.randn(5, 3, 32, 32) # (Batch_size, Num_channels, Height, Width)\n",
    "logits = graph(x)\n",
    "\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46619456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|none~0|+|nor_conv_1x1~0|nor_conv_1x1~1|+|skip_connect~0|none~1|avg_pool_3x3~2|'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import code to convert NASLib graph to the original NAS-Bench-201 representation\n",
    "from naslib.search_spaces.nasbench201.conversions import convert_naslib_to_str as convert_naslib_nb201_to_str\n",
    "\n",
    "# Get the string representation of this model\n",
    "convert_naslib_nb201_to_str(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c46eacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent graph: (1, 3, 0, 3, 1, 4)\n",
      "Child graph : (1, 3, 2, 3, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "# Mutating an architecture\n",
    "# First, create a new child_graph\n",
    "child_graph = NasBench201SearchSpace(n_classes=10)\n",
    "\n",
    "# Call mutate on the child graph by passing the parent graph to it\n",
    "child_graph.mutate(parent=graph)\n",
    "\n",
    "# See the parent and child graph representations\n",
    "print(f'Parent graph: {graph.get_hash()}')\n",
    "print(f'Child graph : {child_graph.get_hash()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9e9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's load the queryable tabular NAS-Bench-201 API\n",
    "# This API has the training metrics of all the 15625 models in the search space\n",
    "# such as train and validation accuracies/losses at every epoch\n",
    "\n",
    "from naslib.utils import get_dataset_api\n",
    "benchmark_api = get_dataset_api(search_space='nasbench201', dataset='cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f539ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of parent model\n",
      "Train accuracy: 98.98800000976563\n",
      "Validation accuracy: 86.11\n"
     ]
    }
   ],
   "source": [
    "# With the NAS-Bench-201 API, we can now query, say, the validation performance of any NB201 model\n",
    "# Without it, we would have to train the model from scratch to get this information\n",
    "\n",
    "# First, import the Metric enum\n",
    "from naslib.search_spaces.core import Metric\n",
    "\n",
    "# Metric has, among others, these values:\n",
    "# Metric.TRAIN_ACCURACY\n",
    "# Metric.VAL_ACCURACY\n",
    "# Metric.TRAIN_LOSS\n",
    "# Metric.TEST_LOSS\n",
    "# Metric.TRAIN_TIME\n",
    "\n",
    "train_acc_parent = graph.query(metric=Metric.TRAIN_ACCURACY, dataset='cifar10', dataset_api=benchmark_api)\n",
    "val_acc_parent = graph.query(metric=Metric.VAL_ACCURACY, dataset='cifar10', dataset_api=benchmark_api)\n",
    "\n",
    "print('Performance of parent model')\n",
    "print(f'Train accuracy: {train_acc_parent}')\n",
    "print(f'Validation accuracy: {val_acc_parent}')\n",
    "\n",
    "# TODO: Query the train and validation performance of the child model\n",
    "# train_acc_parent = ...\n",
    "# val_acc_parent = ...\n",
    "\n",
    "# print('Performance of child model')\n",
    "# print(f'Train accuracy: {train_acc_child}')\n",
    "# print(f'Validation accuracy: {val_acc_child}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15fb7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 1. Sample a random NAS-Bench-301 model\n",
    "# 2. Get the NASLib and genotype representations of the model\n",
    "# 3. Query the predicted performance of the model (loading the NB301 benchmark API might take some time)\n",
    "# 4. Mutate the model\n",
    "# 5. Get the NASLib and genotype representations of the model\n",
    "# 6. Query the predicted performance of the child\n",
    "\n",
    "from naslib.search_spaces import NasBench301SearchSpace\n",
    "from naslib.search_spaces.nasbench301.conversions import convert_naslib_to_genotype as convert_naslib_nb301_to_genotype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c44e30f",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c6c0f6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/13 10:53:16 naslib]: \u001b[0mConfiguration is \n",
      "dataset: cifar10\n",
      "save: runs\n",
      "search:\n",
      "  checkpoint_freq: 100\n",
      "  epochs: 5\n",
      "  fidelity: -1\n",
      "  seed: 0\n",
      "\u001b[32m[09/13 10:53:17 nl.defaults.trainer]: \u001b[0mBeginning search\n",
      "\u001b[32m[09/13 10:53:17 nl.defaults.trainer]: \u001b[0mEpoch 0 done. Train accuracy: 99.11600, Validation accuracy: 86.81000\n",
      "\u001b[32m[09/13 10:53:18 nl.defaults.trainer]: \u001b[0mEpoch 1 done. Train accuracy: 99.55200, Validation accuracy: 84.74000\n",
      "\u001b[32m[09/13 10:53:18 nl.defaults.trainer]: \u001b[0mEpoch 2 done. Train accuracy: 90.96800, Validation accuracy: 84.01000\n",
      "\u001b[32m[09/13 10:53:18 nl.defaults.trainer]: \u001b[0mEpoch 3 done. Train accuracy: 99.16800, Validation accuracy: 84.36000\n",
      "\u001b[32m[09/13 10:53:18 nl.defaults.trainer]: \u001b[0mEpoch 4 done. Train accuracy: 99.96400, Validation accuracy: 90.21000\n",
      "\u001b[32m[09/13 10:53:18 nl.defaults.trainer]: \u001b[0mSaving architectural weight tensors: runs/arch_weights.pt\n",
      "\u001b[32m[09/13 10:53:18 nl.defaults.trainer]: \u001b[0mTraining finished\n",
      "Train accuracies: [99.116, 99.5520000024414, 90.96799999023438, 99.16800000732422, 99.964]\n",
      "Validation accuracies: [86.81, 84.74, 84.01, 84.36, 90.21]\n",
      "\u001b[32m[09/13 10:53:18 nl.defaults.trainer]: \u001b[0mStart evaluation\n",
      "\u001b[32m[09/13 10:53:18 nl.defaults.trainer]: \u001b[0mloading model from file runs\\search\\model_final.pth\n",
      "\u001b[32m[09/13 10:53:18 nl.defaults.trainer]: \u001b[0mFinal architecture hash: (2, 3, 0, 1, 3, 3)\n",
      "\u001b[32m[09/13 10:53:18 nl.defaults.trainer]: \u001b[0mQueried results (Metric.VAL_ACCURACY): 90.21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90.21"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# import the Trainer used to run the optimizer on a given search space\n",
    "from naslib.defaults.trainer import Trainer\n",
    "# import the optimizers\n",
    "from naslib.optimizers import (\n",
    "    RandomSearch,\n",
    "    RegularizedEvolution\n",
    ")\n",
    "# import the search spaces\n",
    "from naslib.search_spaces import (\n",
    "    NasBench101SearchSpace,\n",
    "    NasBench201SearchSpace,\n",
    "    NasBench301SearchSpace,\n",
    ")\n",
    "\n",
    "from naslib.search_spaces.core.query_metrics import Metric\n",
    "from naslib import utils\n",
    "from naslib.utils import get_dataset_api\n",
    "from naslib.utils.log import setup_logger\n",
    "\n",
    "from fvcore.common.config import CfgNode # Required to read the config\n",
    "###### End of imports ######\n",
    "\n",
    "# The configuration used by the Trainer and Optimizer\n",
    "config = {\n",
    "    'dataset': 'cifar10',\n",
    "    'search': {\n",
    "        'seed': 0, # \n",
    "        'epochs': 5, # Number of epochs (steps) of the optimizer to run\n",
    "        'fidelity': -1, # \n",
    "        'checkpoint_freq': 100,\n",
    "    },\n",
    "    'save': 'runs' # folder to save the results to \n",
    "}\n",
    "\n",
    "config = CfgNode.load_cfg(json.dumps(config))\n",
    "\n",
    "# Make the directories required for search and evaluation\n",
    "os.makedirs(config['save'] + '/search', exist_ok=True)\n",
    "os.makedirs(config['save'] + '/eval', exist_ok=True)\n",
    "\n",
    "# Set up the loggers\n",
    "logger = setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# See the config\n",
    "logger.info(f'Configuration is \\n{config}')\n",
    "# logger.info(config)\n",
    "\n",
    "# Set up the seeds\n",
    "utils.set_seed(9002)\n",
    "\n",
    "# Instantiate the search space and get its benchmark API\n",
    "search_space = NasBench201SearchSpace()\n",
    "dataset_api = get_dataset_api('nasbench201', 'cifar10')\n",
    "\n",
    "# Instantitate the optimizer and adapt the search space to it\n",
    "optimizer = RandomSearch(config)\n",
    "optimizer.adapt_search_space(search_space, dataset_api=dataset_api)\n",
    "\n",
    "# Create a Trainer\n",
    "trainer = Trainer(optimizer, config)\n",
    "\n",
    "# Perform the search\n",
    "trainer.search(resume_from=\"\", report_incumbent=False)\n",
    "\n",
    "# Get the results of the search\n",
    "search_trajectory = trainer.search_trajectory\n",
    "print('Train accuracies:', search_trajectory.train_acc)\n",
    "print('Validation accuracies:', search_trajectory.valid_acc)\n",
    "\n",
    "# Get the validation performance of the best model found in the search phase\n",
    "best_model_val_acc = trainer.evaluate(dataset_api=dataset_api, metric=Metric.VAL_ACCURACY)\n",
    "best_model_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "777f232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config(config, optimizer_type, search_space_type, dataset, seed):\n",
    "    # Dataset being used\n",
    "    config.dataset = dataset\n",
    "    \n",
    "    # Directory to which the results/logs will be saved\n",
    "    config.save = f\"runs/{optimizer_type.__name__}/{search_space_type.__name__}/{dataset}/{seed}\"\n",
    "    \n",
    "    # Seed used during search phase of the optimizer\n",
    "    config.search.seed = seed\n",
    "    \n",
    "def run_optimizer(optimizer_type, search_space_type, dataset, dataset_api, config, seed):\n",
    "    # Update the config\n",
    "    update_config(config, optimizer_type, search_space_type, dataset, seed)\n",
    "\n",
    "    # Make the results directories\n",
    "    os.makedirs(config.save + '/search', exist_ok=True)\n",
    "    os.makedirs(config.save + '/eval', exist_ok=True)\n",
    "\n",
    "    # Set up the loggers\n",
    "    logger = setup_logger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "     # See the config\n",
    "    logger.info(f'Configuration is \\n{config}')\n",
    "\n",
    "    # Set up the seed\n",
    "    utils.set_seed(seed)\n",
    "\n",
    "    # Instantiate the search space\n",
    "    n_classes = {\n",
    "        'cifar10': 10,\n",
    "        'cifar100': 100,\n",
    "        'ImageNet16-120': 120\n",
    "    }\n",
    "    search_space = search_space_type(n_classes=n_classes[dataset])\n",
    "\n",
    "    # Get the benchmark API\n",
    "    logger.info('Loading Benchmark API')\n",
    "    dataset_api = get_dataset_api(search_space.get_type(), dataset)\n",
    "    \n",
    "    # Instantiate the optimizer and adapat the search space to the optimizer\n",
    "    optimizer = optimizer_type(config)\n",
    "    optimizer.adapt_search_space(search_space, dataset_api=dataset_api)\n",
    "\n",
    "    # Create a Trainer\n",
    "    trainer = Trainer(optimizer, config)\n",
    "\n",
    "    # Perform the search\n",
    "    trainer.search(report_incumbent=False)\n",
    "\n",
    "    # Get the results of the search\n",
    "    search_trajectory = trainer.search_trajectory\n",
    "    print('Train accuracies:', search_trajectory.train_acc)\n",
    "    print('Validation accuracies:', search_trajectory.valid_acc)\n",
    "\n",
    "    # Get the validation performance of the best model found in the search phase\n",
    "    best_model_val_acc = trainer.evaluate(dataset_api=dataset_api, metric=Metric.VAL_ACCURACY)\n",
    "    best_model_val_acc\n",
    "\n",
    "    best_model = optimizer.get_final_architecture()\n",
    "\n",
    "    return search_trajectory, best_model, best_model_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b15fd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/13 10:53:34 naslib]: \u001b[0mConfiguration is \n",
      "dataset: cifar100\n",
      "save: runs/RegularizedEvolution/NasBench201SearchSpace/cifar100/9001\n",
      "search:\n",
      "  checkpoint_freq: 100\n",
      "  epochs: 100\n",
      "  fidelity: -1\n",
      "  population_size: 30\n",
      "  sample_size: 10\n",
      "  seed: 9001\n",
      "\u001b[32m[09/13 10:53:34 naslib]: \u001b[0mLoading Benchmark API\n",
      "\u001b[32m[09/13 10:53:35 nl.defaults.trainer]: \u001b[0mBeginning search\n",
      "\u001b[32m[09/13 10:53:35 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:35 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 1\n",
      "\u001b[32m[09/13 10:53:35 nl.defaults.trainer]: \u001b[0mEpoch 0 done. Train accuracy: 52.72400, Validation accuracy: 49.34000\n",
      "\u001b[32m[09/13 10:53:35 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:35 nl.defaults.trainer]: \u001b[0mEpoch 1 done. Train accuracy: 79.93000, Validation accuracy: 67.04000\n",
      "\u001b[32m[09/13 10:53:35 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:36 nl.defaults.trainer]: \u001b[0mEpoch 2 done. Train accuracy: 93.48600, Validation accuracy: 68.88000\n",
      "\u001b[32m[09/13 10:53:36 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:36 nl.defaults.trainer]: \u001b[0mEpoch 3 done. Train accuracy: 52.53400, Validation accuracy: 46.82000\n",
      "\u001b[32m[09/13 10:53:36 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:36 nl.defaults.trainer]: \u001b[0mEpoch 4 done. Train accuracy: 89.78200, Validation accuracy: 64.74000\n",
      "\u001b[32m[09/13 10:53:36 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:37 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 6\n",
      "\u001b[32m[09/13 10:53:37 nl.defaults.trainer]: \u001b[0mEpoch 5 done. Train accuracy: 97.18600, Validation accuracy: 69.66000\n",
      "\u001b[32m[09/13 10:53:37 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:37 nl.defaults.trainer]: \u001b[0mEpoch 6 done. Train accuracy: 94.49000, Validation accuracy: 68.68000\n",
      "\u001b[32m[09/13 10:53:37 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:37 nl.defaults.trainer]: \u001b[0mEpoch 7 done. Train accuracy: 78.16400, Validation accuracy: 64.80000\n",
      "\u001b[32m[09/13 10:53:37 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:37 nl.defaults.trainer]: \u001b[0mEpoch 8 done. Train accuracy: 63.54800, Validation accuracy: 59.04000\n",
      "\u001b[32m[09/13 10:53:37 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:37 nl.defaults.trainer]: \u001b[0mEpoch 9 done. Train accuracy: 70.95400, Validation accuracy: 61.00000\n",
      "\u001b[32m[09/13 10:53:37 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:37 nl.defaults.trainer]: \u001b[0mEpoch 10 done. Train accuracy: 52.42200, Validation accuracy: 47.96000\n",
      "\u001b[32m[09/13 10:53:37 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:37 nl.defaults.trainer]: \u001b[0mEpoch 11 done. Train accuracy: 92.03400, Validation accuracy: 67.38000\n",
      "\u001b[32m[09/13 10:53:37 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:38 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 13\n",
      "\u001b[32m[09/13 10:53:38 nl.defaults.trainer]: \u001b[0mEpoch 12 done. Train accuracy: 99.74800, Validation accuracy: 72.08000\n",
      "\u001b[32m[09/13 10:53:38 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:38 nl.defaults.trainer]: \u001b[0mEpoch 13 done. Train accuracy: 71.65400, Validation accuracy: 62.00000\n",
      "\u001b[32m[09/13 10:53:38 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:38 nl.defaults.trainer]: \u001b[0mEpoch 14 done. Train accuracy: 54.32000, Validation accuracy: 50.12000\n",
      "\u001b[32m[09/13 10:53:38 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:38 nl.defaults.trainer]: \u001b[0mEpoch 15 done. Train accuracy: 81.85200, Validation accuracy: 62.50000\n",
      "\u001b[32m[09/13 10:53:38 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:39 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 17\n",
      "\u001b[32m[09/13 10:53:39 nl.defaults.trainer]: \u001b[0mEpoch 16 done. Train accuracy: 75.36000, Validation accuracy: 57.16000\n",
      "\u001b[32m[09/13 10:53:39 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:39 nl.defaults.trainer]: \u001b[0mEpoch 17 done. Train accuracy: 62.25800, Validation accuracy: 55.80000\n",
      "\u001b[32m[09/13 10:53:39 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:39 nl.defaults.trainer]: \u001b[0mEpoch 18 done. Train accuracy: 91.05600, Validation accuracy: 66.98000\n",
      "\u001b[32m[09/13 10:53:39 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:39 nl.defaults.trainer]: \u001b[0mEpoch 19 done. Train accuracy: 93.72600, Validation accuracy: 63.74000\n",
      "\u001b[32m[09/13 10:53:39 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:39 nl.defaults.trainer]: \u001b[0mEpoch 20 done. Train accuracy: 52.24000, Validation accuracy: 46.68000\n",
      "\u001b[32m[09/13 10:53:39 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:39 nl.defaults.trainer]: \u001b[0mEpoch 21 done. Train accuracy: 94.96000, Validation accuracy: 65.56000\n",
      "\u001b[32m[09/13 10:53:39 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:40 nl.defaults.trainer]: \u001b[0mEpoch 22 done. Train accuracy: 78.60200, Validation accuracy: 64.68000\n",
      "\u001b[32m[09/13 10:53:40 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:40 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 24\n",
      "\u001b[32m[09/13 10:53:40 nl.defaults.trainer]: \u001b[0mEpoch 23 done. Train accuracy: 90.94200, Validation accuracy: 65.72000\n",
      "\u001b[32m[09/13 10:53:40 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:40 nl.defaults.trainer]: \u001b[0mEpoch 24 done. Train accuracy: 83.87800, Validation accuracy: 64.52000\n",
      "\u001b[32m[09/13 10:53:40 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:40 nl.defaults.trainer]: \u001b[0mEpoch 25 done. Train accuracy: 62.94200, Validation accuracy: 56.10000\n",
      "\u001b[32m[09/13 10:53:40 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:41 nl.defaults.trainer]: \u001b[0mEpoch 26 done. Train accuracy: 95.70000, Validation accuracy: 67.28000\n",
      "\u001b[32m[09/13 10:53:41 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:41 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 28\n",
      "\u001b[32m[09/13 10:53:41 nl.defaults.trainer]: \u001b[0mEpoch 27 done. Train accuracy: 92.09800, Validation accuracy: 66.62000\n",
      "\u001b[32m[09/13 10:53:41 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:41 nl.defaults.trainer]: \u001b[0mEpoch 28 done. Train accuracy: 71.35000, Validation accuracy: 61.78000\n",
      "\u001b[32m[09/13 10:53:41 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n",
      "\u001b[32m[09/13 10:53:41 nl.defaults.trainer]: \u001b[0mEpoch 29 done. Train accuracy: 9.81600, Validation accuracy: 10.18000\n",
      "\u001b[32m[09/13 10:53:41 nl.defaults.trainer]: \u001b[0mEpoch 30 done. Train accuracy: 91.62000, Validation accuracy: 65.20000\n",
      "\u001b[32m[09/13 10:53:41 nl.defaults.trainer]: \u001b[0mEpoch 31 done. Train accuracy: 99.18600, Validation accuracy: 70.76000\n",
      "\u001b[32m[09/13 10:53:42 nl.defaults.trainer]: \u001b[0mEpoch 32 done. Train accuracy: 91.25000, Validation accuracy: 67.16000\n",
      "\u001b[32m[09/13 10:53:42 nl.defaults.trainer]: \u001b[0mEpoch 33 done. Train accuracy: 89.42400, Validation accuracy: 65.62000\n",
      "\u001b[32m[09/13 10:53:42 nl.defaults.trainer]: \u001b[0mEpoch 34 done. Train accuracy: 96.00600, Validation accuracy: 65.80000\n",
      "\u001b[32m[09/13 10:53:42 nl.defaults.trainer]: \u001b[0mEpoch 35 done. Train accuracy: 99.66400, Validation accuracy: 70.62000\n",
      "\u001b[32m[09/13 10:53:42 nl.defaults.trainer]: \u001b[0mEpoch 36 done. Train accuracy: 99.66400, Validation accuracy: 70.62000\n",
      "\u001b[32m[09/13 10:53:42 nl.defaults.trainer]: \u001b[0mEpoch 37 done. Train accuracy: 98.77600, Validation accuracy: 70.64000\n",
      "\u001b[32m[09/13 10:53:43 nl.defaults.trainer]: \u001b[0mEpoch 38 done. Train accuracy: 94.56400, Validation accuracy: 67.10000\n",
      "\u001b[32m[09/13 10:53:43 nl.defaults.trainer]: \u001b[0mEpoch 39 done. Train accuracy: 87.67000, Validation accuracy: 63.88000\n",
      "\u001b[32m[09/13 10:53:43 nl.defaults.trainer]: \u001b[0mEpoch 40 done. Train accuracy: 99.86600, Validation accuracy: 70.40000\n",
      "\u001b[32m[09/13 10:53:44 nl.defaults.trainer]: \u001b[0mEpoch 41 done. Train accuracy: 99.03200, Validation accuracy: 69.68000\n",
      "\u001b[32m[09/13 10:53:44 nl.defaults.trainer]: \u001b[0mEpoch 42 done. Train accuracy: 99.72800, Validation accuracy: 70.88000\n",
      "\u001b[32m[09/13 10:53:44 nl.defaults.trainer]: \u001b[0mEpoch 43 done. Train accuracy: 97.89400, Validation accuracy: 69.62000\n",
      "\u001b[32m[09/13 10:53:44 nl.defaults.trainer]: \u001b[0mEpoch 44 done. Train accuracy: 98.11000, Validation accuracy: 66.68000\n",
      "\u001b[32m[09/13 10:53:44 nl.defaults.trainer]: \u001b[0mEpoch 45 done. Train accuracy: 99.08400, Validation accuracy: 70.88000\n",
      "\u001b[32m[09/13 10:53:44 nl.defaults.trainer]: \u001b[0mEpoch 46 done. Train accuracy: 94.13400, Validation accuracy: 68.38000\n",
      "\u001b[32m[09/13 10:53:44 nl.defaults.trainer]: \u001b[0mEpoch 47 done. Train accuracy: 99.60400, Validation accuracy: 71.46000\n",
      "\u001b[32m[09/13 10:53:45 nl.defaults.trainer]: \u001b[0mEpoch 48 done. Train accuracy: 90.77000, Validation accuracy: 67.46000\n",
      "\u001b[32m[09/13 10:53:45 nl.defaults.trainer]: \u001b[0mEpoch 49 done. Train accuracy: 87.58000, Validation accuracy: 67.24000\n",
      "\u001b[32m[09/13 10:53:45 nl.defaults.trainer]: \u001b[0mEpoch 50 done. Train accuracy: 99.66400, Validation accuracy: 70.62000\n",
      "\u001b[32m[09/13 10:53:45 nl.defaults.trainer]: \u001b[0mEpoch 51 done. Train accuracy: 98.84800, Validation accuracy: 69.72000\n",
      "\u001b[32m[09/13 10:53:45 nl.defaults.trainer]: \u001b[0mEpoch 52 done. Train accuracy: 98.70800, Validation accuracy: 68.74000\n",
      "\u001b[32m[09/13 10:53:46 nl.defaults.trainer]: \u001b[0mEpoch 53 done. Train accuracy: 99.63400, Validation accuracy: 70.44000\n",
      "\u001b[32m[09/13 10:53:46 nl.defaults.trainer]: \u001b[0mEpoch 54 done. Train accuracy: 99.44400, Validation accuracy: 70.40000\n",
      "\u001b[32m[09/13 10:53:46 nl.defaults.trainer]: \u001b[0mEpoch 55 done. Train accuracy: 98.96800, Validation accuracy: 69.86000\n",
      "\u001b[32m[09/13 10:53:47 nl.defaults.trainer]: \u001b[0mEpoch 56 done. Train accuracy: 98.84400, Validation accuracy: 68.62000\n",
      "\u001b[32m[09/13 10:53:47 nl.defaults.trainer]: \u001b[0mEpoch 57 done. Train accuracy: 99.27000, Validation accuracy: 70.42000\n",
      "\u001b[32m[09/13 10:53:47 nl.defaults.trainer]: \u001b[0mEpoch 58 done. Train accuracy: 98.59400, Validation accuracy: 69.34000\n",
      "\u001b[32m[09/13 10:53:47 nl.defaults.trainer]: \u001b[0mEpoch 59 done. Train accuracy: 98.96800, Validation accuracy: 69.86000\n",
      "\u001b[32m[09/13 10:53:47 nl.defaults.trainer]: \u001b[0mEpoch 60 done. Train accuracy: 98.83800, Validation accuracy: 71.14000\n",
      "\u001b[32m[09/13 10:53:47 nl.defaults.trainer]: \u001b[0mEpoch 61 done. Train accuracy: 99.60400, Validation accuracy: 71.46000\n",
      "\u001b[32m[09/13 10:53:48 nl.defaults.trainer]: \u001b[0mEpoch 62 done. Train accuracy: 99.39000, Validation accuracy: 71.62000\n",
      "\u001b[32m[09/13 10:53:48 nl.defaults.trainer]: \u001b[0mEpoch 63 done. Train accuracy: 99.22000, Validation accuracy: 71.18000\n",
      "\u001b[32m[09/13 10:53:48 nl.defaults.trainer]: \u001b[0mEpoch 64 done. Train accuracy: 99.22000, Validation accuracy: 71.18000\n",
      "\u001b[32m[09/13 10:53:48 nl.defaults.trainer]: \u001b[0mEpoch 65 done. Train accuracy: 97.90600, Validation accuracy: 69.74000\n",
      "\u001b[32m[09/13 10:53:48 nl.defaults.trainer]: \u001b[0mEpoch 66 done. Train accuracy: 99.75600, Validation accuracy: 70.24000\n",
      "\u001b[32m[09/13 10:53:48 nl.defaults.trainer]: \u001b[0mEpoch 67 done. Train accuracy: 97.74800, Validation accuracy: 69.78000\n",
      "\u001b[32m[09/13 10:53:49 nl.defaults.trainer]: \u001b[0mEpoch 68 done. Train accuracy: 98.55600, Validation accuracy: 69.90000\n",
      "\u001b[32m[09/13 10:53:49 nl.defaults.trainer]: \u001b[0mEpoch 69 done. Train accuracy: 97.95000, Validation accuracy: 70.16000\n",
      "\u001b[32m[09/13 10:53:50 nl.defaults.trainer]: \u001b[0mEpoch 70 done. Train accuracy: 97.70400, Validation accuracy: 68.68000\n",
      "\u001b[32m[09/13 10:53:50 nl.defaults.trainer]: \u001b[0mEpoch 71 done. Train accuracy: 98.78600, Validation accuracy: 70.38000\n",
      "\u001b[32m[09/13 10:53:50 nl.defaults.trainer]: \u001b[0mEpoch 72 done. Train accuracy: 97.42000, Validation accuracy: 69.52000\n",
      "\u001b[32m[09/13 10:53:50 nl.defaults.trainer]: \u001b[0mEpoch 73 done. Train accuracy: 97.53200, Validation accuracy: 70.22000\n",
      "\u001b[32m[09/13 10:53:50 nl.defaults.trainer]: \u001b[0mEpoch 74 done. Train accuracy: 97.52200, Validation accuracy: 68.76000\n",
      "\u001b[32m[09/13 10:53:50 nl.defaults.trainer]: \u001b[0mEpoch 75 done. Train accuracy: 99.65200, Validation accuracy: 71.56000\n",
      "\u001b[32m[09/13 10:53:51 nl.defaults.trainer]: \u001b[0mEpoch 76 done. Train accuracy: 96.90800, Validation accuracy: 69.68000\n",
      "\u001b[32m[09/13 10:53:51 nl.defaults.trainer]: \u001b[0mEpoch 77 done. Train accuracy: 98.67400, Validation accuracy: 69.88000\n",
      "\u001b[32m[09/13 10:53:51 nl.defaults.trainer]: \u001b[0mEpoch 78 done. Train accuracy: 99.07200, Validation accuracy: 70.64000\n",
      "\u001b[32m[09/13 10:53:51 nl.defaults.trainer]: \u001b[0mEpoch 79 done. Train accuracy: 98.99800, Validation accuracy: 69.96000\n",
      "\u001b[32m[09/13 10:53:51 nl.defaults.trainer]: \u001b[0mEpoch 80 done. Train accuracy: 98.93600, Validation accuracy: 70.84000\n",
      "\u001b[32m[09/13 10:53:51 nl.defaults.trainer]: \u001b[0mEpoch 81 done. Train accuracy: 99.34400, Validation accuracy: 71.42000\n",
      "\u001b[32m[09/13 10:53:52 nl.defaults.trainer]: \u001b[0mEpoch 82 done. Train accuracy: 96.33800, Validation accuracy: 64.76000\n",
      "\u001b[32m[09/13 10:53:52 nl.defaults.trainer]: \u001b[0mEpoch 83 done. Train accuracy: 95.15800, Validation accuracy: 68.80000\n",
      "\u001b[32m[09/13 10:53:52 nl.defaults.trainer]: \u001b[0mEpoch 84 done. Train accuracy: 95.55000, Validation accuracy: 68.66000\n",
      "\u001b[32m[09/13 10:53:52 nl.defaults.trainer]: \u001b[0mEpoch 85 done. Train accuracy: 97.61400, Validation accuracy: 69.46000\n",
      "\u001b[32m[09/13 10:53:52 nl.defaults.trainer]: \u001b[0mEpoch 86 done. Train accuracy: 98.05400, Validation accuracy: 69.92000\n",
      "\u001b[32m[09/13 10:53:52 nl.defaults.trainer]: \u001b[0mEpoch 87 done. Train accuracy: 99.87000, Validation accuracy: 72.14000\n",
      "\u001b[32m[09/13 10:53:53 nl.defaults.trainer]: \u001b[0mEpoch 88 done. Train accuracy: 99.52400, Validation accuracy: 71.24000\n",
      "\u001b[32m[09/13 10:53:53 nl.defaults.trainer]: \u001b[0mEpoch 89 done. Train accuracy: 99.63400, Validation accuracy: 70.44000\n",
      "\u001b[32m[09/13 10:53:54 nl.defaults.trainer]: \u001b[0mEpoch 90 done. Train accuracy: 99.66400, Validation accuracy: 70.62000\n",
      "\u001b[32m[09/13 10:53:54 nl.defaults.trainer]: \u001b[0mEpoch 91 done. Train accuracy: 99.63400, Validation accuracy: 70.44000\n",
      "\u001b[32m[09/13 10:53:54 nl.defaults.trainer]: \u001b[0mEpoch 92 done. Train accuracy: 82.36800, Validation accuracy: 63.80000\n",
      "\u001b[32m[09/13 10:53:54 nl.defaults.trainer]: \u001b[0mEpoch 93 done. Train accuracy: 99.52400, Validation accuracy: 71.24000\n",
      "\u001b[32m[09/13 10:53:54 nl.defaults.trainer]: \u001b[0mEpoch 94 done. Train accuracy: 99.14600, Validation accuracy: 68.44000\n",
      "\u001b[32m[09/13 10:53:55 nl.defaults.trainer]: \u001b[0mEpoch 95 done. Train accuracy: 99.35800, Validation accuracy: 68.82000\n",
      "\u001b[32m[09/13 10:53:55 nl.defaults.trainer]: \u001b[0mEpoch 96 done. Train accuracy: 96.78400, Validation accuracy: 70.66000\n",
      "\u001b[32m[09/13 10:53:55 nl.defaults.trainer]: \u001b[0mEpoch 97 done. Train accuracy: 99.14600, Validation accuracy: 68.44000\n",
      "\u001b[32m[09/13 10:53:55 nl.defaults.trainer]: \u001b[0mEpoch 98 done. Train accuracy: 99.04600, Validation accuracy: 69.38000\n",
      "\u001b[32m[09/13 10:53:55 nl.defaults.trainer]: \u001b[0mEpoch 99 done. Train accuracy: 90.67800, Validation accuracy: 67.34000\n",
      "\u001b[32m[09/13 10:53:55 nl.defaults.trainer]: \u001b[0mSaving architectural weight tensors: runs/RegularizedEvolution/NasBench201SearchSpace/cifar100/9001/arch_weights.pt\n",
      "\u001b[32m[09/13 10:53:55 nl.defaults.trainer]: \u001b[0mTraining finished\n",
      "Train accuracies: [52.724, 79.93, 93.486, 52.534, 89.782, 97.186, 94.49, 78.164, 63.548, 70.954, 52.422, 92.034, 99.748, 71.654, 54.32, 81.852, 75.36, 62.258, 91.056, 93.726, 52.24, 94.96, 78.602, 90.942, 83.878, 62.942, 95.7, 92.098, 71.35, 9.816, 91.62, 99.186, 91.25, 89.424, 96.006, 99.664, 99.664, 98.776, 94.564, 87.67, 99.866, 99.032, 99.728, 97.894, 98.11, 99.084, 94.134, 99.604, 90.77, 87.58, 99.664, 98.848, 98.708, 99.634, 99.444, 98.968, 98.844, 99.27, 98.594, 98.968, 98.838, 99.604, 99.39, 99.22, 99.22, 97.906, 99.756, 97.748, 98.556, 97.95, 97.704, 98.786, 97.42, 97.532, 97.522, 99.652, 96.908, 98.674, 99.072, 98.998, 98.936, 99.344, 96.338, 95.158, 95.55, 97.614, 98.054, 99.87, 99.524, 99.634, 99.664, 99.634, 82.368, 99.524, 99.146, 99.358, 96.784, 99.146, 99.046, 90.678]\n",
      "Validation accuracies: [49.34000001831055, 67.04, 68.87999992675782, 46.82000001220703, 64.73999992675782, 69.65999990234376, 68.67999995117188, 64.79999999389648, 59.04000002441406, 60.999999981689456, 47.95999998779297, 67.38000006103516, 72.08000006103515, 61.99999992675781, 50.119999938964845, 62.49999995117187, 57.16, 55.799999932861326, 66.98000000610351, 63.74000003662109, 46.679999926757816, 65.55999992675781, 64.67999998779297, 65.71999992675781, 64.51999987792969, 56.099999969482425, 67.27999996337891, 66.61999993896484, 61.7800000366211, 10.179999996185304, 65.2, 70.75999986572266, 67.15999987792969, 65.62000001220703, 65.79999990234376, 70.6200000366211, 70.6200000366211, 70.64000004882813, 67.09999997558593, 63.879999951171875, 70.40000006103516, 69.67999997558594, 70.87999995117187, 69.6199999633789, 66.68000002441406, 70.88000001220703, 68.38, 71.45999991455078, 67.46, 67.23999992675782, 70.6200000366211, 69.72000002441406, 68.73999991455078, 70.43999986572265, 70.39999990234375, 69.86000004882813, 68.61999986572266, 70.42, 69.33999993896484, 69.86000004882813, 71.13999998779298, 71.45999991455078, 71.61999998779297, 71.18000004882812, 71.18000004882812, 69.7400000366211, 70.24000004882812, 69.77999996337891, 69.90000006103516, 70.16000002441406, 68.68000001220703, 70.37999998779297, 69.52000004882812, 70.21999996337891, 68.75999997558594, 71.56000006103515, 69.67999987792969, 69.87999993896484, 70.63999996337891, 69.95999989013671, 70.83999986572266, 71.41999992675781, 64.7599999572754, 68.80000004882812, 68.65999996337891, 69.45999993896484, 69.92000003662109, 72.13999992675781, 71.23999986572265, 70.43999986572265, 70.6200000366211, 70.43999986572265, 63.79999997558594, 71.23999986572265, 68.4400000366211, 68.81999991455078, 70.65999995117187, 68.4400000366211, 69.37999993896484, 67.34000003662109]\n",
      "\u001b[32m[09/13 10:53:55 nl.defaults.trainer]: \u001b[0mStart evaluation\n",
      "\u001b[32m[09/13 10:53:55 nl.defaults.trainer]: \u001b[0mloading model from file runs/RegularizedEvolution/NasBench201SearchSpace/cifar100/9001\\search\\model_final.pth\n",
      "\u001b[32m[09/13 10:53:55 nl.defaults.trainer]: \u001b[0mFinal architecture hash: (2, 2, 0, 2, 4, 2)\n",
      "\u001b[32m[09/13 10:53:55 nl.defaults.trainer]: \u001b[0mQueried results (Metric.VAL_ACCURACY): 72.13999992675781\n"
     ]
    }
   ],
   "source": [
    "# Set the optimizer and search space types\n",
    "# They will be instantiated inside run_optimizer\n",
    "optimizer_type = RegularizedEvolution # {RegularizedEvolution, RandomSearch}\n",
    "search_space_type = NasBench201SearchSpace # {NasBench101SearchSpace, NasBench201SearchSpace, NasBench301SearchSpace}\n",
    "\n",
    "# Set the dataset\n",
    "dataset = 'cifar100' # cifar10 for NB101 and NB301, {cifar100, ImageNet16-120} for NB201\n",
    "\n",
    "# The configuration used by the Trainer and Optimizer\n",
    "# The missing information will be populated inside run_optimizer\n",
    "config = {\n",
    "    'search': {\n",
    "        # Required by Trainer\n",
    "        'epochs': 100,\n",
    "        'checkpoint_freq': 100,\n",
    "        \n",
    "        # Required by Random Search optimizer\n",
    "        'fidelity': -1,\n",
    "        \n",
    "        # Required by RegularizedEvolution\n",
    "        'sample_size': 10,\n",
    "        'population_size': 30,\n",
    "    }\n",
    "}\n",
    "config = CfgNode.load_cfg(json.dumps(config))\n",
    "\n",
    "search_trajectory, best_model, best_model_val_acc = run_optimizer(\n",
    "                                                        optimizer_type,\n",
    "                                                        search_space_type,\n",
    "                                                        dataset,\n",
    "                                                        dataset_api,\n",
    "                                                        config,\n",
    "                                                        9001\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea257c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e8686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a138bae05203fa8eb4bf07493da4bb9038fdb3e1f2f10b7ab3cd8c9223b9122"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
